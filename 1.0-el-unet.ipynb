{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELU-net construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/elunet_arch.png\"  width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU-Net Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\" [(Conv2d) => (BN) => (ReLu)] * 2 \"\"\"\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels) -> None:\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels,out_channels,3,padding=\"same\",stride=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels,out_channels,3,padding=\"same\",stride=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()      \n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "    \"\"\" MaxPool => DoubleConv \"\"\"\n",
    "    def __init__(self,in_channels,out_channels) -> None:\n",
    "        super().__init__()\n",
    "        self.down_sample = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels,out_channels)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x  = self.down_sample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,c:int) -> None:\n",
    "        \"\"\" UpSample input tensor by a factor of `c`\n",
    "                - the value of base 2 log c defines the number of upsample \n",
    "                layers that will be applied\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        n = 0 if n == 0 else int(math.log(c,2))\n",
    "\n",
    "        self.upsample = nn.ModuleList(\n",
    "            [nn.ConvTranspose2d(in_channels,in_channels,2,2) for i in range(n)]\n",
    "        )\n",
    "        self.conv_3 = nn.Conv2d(in_channels,out_channels,3,padding=\"same\",stride=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.upsample:\n",
    "            x = layer(x)\n",
    "        return self.conv_3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct ELUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELUnet(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels) -> None:\n",
    "        super().__init__()\n",
    "        # ------ Input convolution --------------\n",
    "        self.in_conv = DoubleConv(in_channels,64)\n",
    "        # -------- Encoder ----------------------\n",
    "        self.down_1 = DownSample(64,128)\n",
    "        self.down_2 = DownSample(128,256)\n",
    "        self.down_3 = DownSample(256,512)\n",
    "        self.down_4 = DownSample(512,1024)\n",
    "        \n",
    "        # -------- Upsampling ------------------\n",
    "        self.up_1024_512 = UpSample(1024,512,2)\n",
    "\n",
    "        self.up_512_64 = UpSample(512,64,8)\n",
    "        self.up_512_128 = UpSample(512,128,4)\n",
    "        self.up_512_256 = UpSample(512,256,2)\n",
    "        self.up_512_512 = UpSample(512,512,0)\n",
    "\n",
    "        self.up_256_64 = UpSample(256,64,4)\n",
    "        self.up_256_128 = UpSample(256,128,2)\n",
    "        self.up_256_256 = UpSample(256,256,0)\n",
    "\n",
    "        self.up_128_64 = UpSample(128,64,2)\n",
    "        self.up_128_128 = UpSample(128,128,0)\n",
    "\n",
    "        self.up_64_64 = UpSample(64,64,0)\n",
    "     \n",
    "        # ------ Decoder block ---------------\n",
    "        self.dec_4 = DoubleConv(1024,512)\n",
    "        self.dec_3 = DoubleConv(768,256)\n",
    "        self.dec_2 = DoubleConv(512,128)\n",
    "        self.dec_1 = DoubleConv(320,64)\n",
    "        # ------ Output convolution\n",
    "\n",
    "        self.out_conv = DoubleConv(64,out_channels)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.in_conv(x) # 64\n",
    "        # ---- Encoder outputs\n",
    "        x_enc_1 = self.down_1(x) # 128\n",
    "        x_enc_2 = self.down_2(x_enc_1) # 256\n",
    "        x_enc_3 = self.down_3(x_enc_2) # 512\n",
    "        x_enc_4 = self.down_4(x_enc_3) # 1024\n",
    "    \n",
    "        # ------ decoder outputs\n",
    "        x_up_1 = self.up_1024_512(x_enc_4)\n",
    "        x_dec_4 = self.dec_4(torch.cat([x_up_1,self.up_512_512(x_enc_3)],dim=1))\n",
    "\n",
    "        x_up_2 = self.up_512_256(x_dec_4)\n",
    "        x_dec_3 = self.dec_3(torch.cat([x_up_2,\n",
    "            self.up_512_256(x_enc_3),\n",
    "            self.up_256_256(x_enc_2)\n",
    "            ],\n",
    "        dim=1))\n",
    "\n",
    "        x_up_3 = self.up_256_128(x_dec_3)\n",
    "        x_dec_2 = self.dec_2(torch.cat([\n",
    "            x_up_3,\n",
    "            self.up_512_128(x_enc_3),\n",
    "            self.up_256_128(x_enc_2),\n",
    "            self.up_128_128(x_enc_1)\n",
    "        ],dim=1))\n",
    "\n",
    "        x_up_4 = self.up_128_64(x_dec_2)\n",
    "        x_dec_1 = self.dec_1(torch.cat([\n",
    "            x_up_4,\n",
    "            self.up_512_64(x_enc_3),\n",
    "            self.up_256_64(x_enc_2),\n",
    "            self.up_128_64(x_enc_1),\n",
    "            self.up_64_64(x)\n",
    "        ],dim=1))\n",
    "\n",
    "        return self.out_conv(x_dec_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elunet = ELUnet(1,3)\n",
    "x = torch.randn(1,1,256,256)\n",
    "elunet(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()\n",
    "tb.add_graph(elunet,x)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 128, 128])\n",
      "torch.Size([2, 256, 64, 64])\n",
      "torch.Size([2, 512, 32, 32])\n",
      "torch.Size([2, 1024, 16, 16])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "        DoubleConv-7         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-8         [-1, 64, 128, 128]               0\n",
      "            Conv2d-9        [-1, 128, 128, 128]          73,856\n",
      "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
      "             ReLU-11        [-1, 128, 128, 128]               0\n",
      "           Conv2d-12        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
      "             ReLU-14        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-15        [-1, 128, 128, 128]               0\n",
      "       DownSample-16        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-17          [-1, 128, 64, 64]               0\n",
      "           Conv2d-18          [-1, 256, 64, 64]         295,168\n",
      "      BatchNorm2d-19          [-1, 256, 64, 64]             512\n",
      "             ReLU-20          [-1, 256, 64, 64]               0\n",
      "           Conv2d-21          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 64, 64]             512\n",
      "             ReLU-23          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-24          [-1, 256, 64, 64]               0\n",
      "       DownSample-25          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27          [-1, 512, 32, 32]       1,180,160\n",
      "      BatchNorm2d-28          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-29          [-1, 512, 32, 32]               0\n",
      "           Conv2d-30          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-31          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-32          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-33          [-1, 512, 32, 32]               0\n",
      "       DownSample-34          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-35          [-1, 512, 16, 16]               0\n",
      "           Conv2d-36         [-1, 1024, 16, 16]       4,719,616\n",
      "      BatchNorm2d-37         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-38         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-39         [-1, 1024, 16, 16]       9,438,208\n",
      "      BatchNorm2d-40         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-41         [-1, 1024, 16, 16]               0\n",
      "       DoubleConv-42         [-1, 1024, 16, 16]               0\n",
      "       DownSample-43         [-1, 1024, 16, 16]               0\n",
      "  ConvTranspose2d-44         [-1, 1024, 32, 32]       4,195,328\n",
      "           Conv2d-45          [-1, 512, 32, 32]       4,719,104\n",
      "         UpSample-46          [-1, 512, 32, 32]               0\n",
      "           Conv2d-47          [-1, 512, 32, 32]       2,359,808\n",
      "         UpSample-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 512, 32, 32]       4,719,104\n",
      "      BatchNorm2d-50          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-51          [-1, 512, 32, 32]               0\n",
      "           Conv2d-52          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-53          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-54          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-55          [-1, 512, 32, 32]               0\n",
      "  ConvTranspose2d-56          [-1, 512, 64, 64]       1,049,088\n",
      "           Conv2d-57          [-1, 256, 64, 64]       1,179,904\n",
      "         UpSample-58          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-59          [-1, 512, 64, 64]       1,049,088\n",
      "           Conv2d-60          [-1, 256, 64, 64]       1,179,904\n",
      "         UpSample-61          [-1, 256, 64, 64]               0\n",
      "           Conv2d-62          [-1, 256, 64, 64]         590,080\n",
      "         UpSample-63          [-1, 256, 64, 64]               0\n",
      "           Conv2d-64          [-1, 256, 64, 64]       1,769,728\n",
      "      BatchNorm2d-65          [-1, 256, 64, 64]             512\n",
      "             ReLU-66          [-1, 256, 64, 64]               0\n",
      "           Conv2d-67          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-68          [-1, 256, 64, 64]             512\n",
      "             ReLU-69          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-70          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-71        [-1, 256, 128, 128]         262,400\n",
      "           Conv2d-72        [-1, 128, 128, 128]         295,040\n",
      "         UpSample-73        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-74          [-1, 512, 64, 64]       1,049,088\n",
      "  ConvTranspose2d-75        [-1, 512, 128, 128]       1,049,088\n",
      "           Conv2d-76        [-1, 128, 128, 128]         589,952\n",
      "         UpSample-77        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-78        [-1, 256, 128, 128]         262,400\n",
      "           Conv2d-79        [-1, 128, 128, 128]         295,040\n",
      "         UpSample-80        [-1, 128, 128, 128]               0\n",
      "           Conv2d-81        [-1, 128, 128, 128]         147,584\n",
      "         UpSample-82        [-1, 128, 128, 128]               0\n",
      "           Conv2d-83        [-1, 128, 128, 128]         589,952\n",
      "      BatchNorm2d-84        [-1, 128, 128, 128]             256\n",
      "             ReLU-85        [-1, 128, 128, 128]               0\n",
      "           Conv2d-86        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-87        [-1, 128, 128, 128]             256\n",
      "             ReLU-88        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-89        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-90        [-1, 128, 256, 256]          65,664\n",
      "           Conv2d-91         [-1, 64, 256, 256]          73,792\n",
      "         UpSample-92         [-1, 64, 256, 256]               0\n",
      "  ConvTranspose2d-93          [-1, 512, 64, 64]       1,049,088\n",
      "  ConvTranspose2d-94        [-1, 512, 128, 128]       1,049,088\n",
      "  ConvTranspose2d-95        [-1, 512, 256, 256]       1,049,088\n",
      "           Conv2d-96         [-1, 64, 256, 256]         294,976\n",
      "         UpSample-97         [-1, 64, 256, 256]               0\n",
      "  ConvTranspose2d-98        [-1, 256, 128, 128]         262,400\n",
      "  ConvTranspose2d-99        [-1, 256, 256, 256]         262,400\n",
      "          Conv2d-100         [-1, 64, 256, 256]         147,520\n",
      "        UpSample-101         [-1, 64, 256, 256]               0\n",
      " ConvTranspose2d-102        [-1, 128, 256, 256]          65,664\n",
      "          Conv2d-103         [-1, 64, 256, 256]          73,792\n",
      "        UpSample-104         [-1, 64, 256, 256]               0\n",
      "          Conv2d-105         [-1, 64, 256, 256]          36,928\n",
      "        UpSample-106         [-1, 64, 256, 256]               0\n",
      "          Conv2d-107         [-1, 64, 256, 256]         184,384\n",
      "     BatchNorm2d-108         [-1, 64, 256, 256]             128\n",
      "            ReLU-109         [-1, 64, 256, 256]               0\n",
      "          Conv2d-110         [-1, 64, 256, 256]          36,928\n",
      "     BatchNorm2d-111         [-1, 64, 256, 256]             128\n",
      "            ReLU-112         [-1, 64, 256, 256]               0\n",
      "      DoubleConv-113         [-1, 64, 256, 256]               0\n",
      "          Conv2d-114          [-1, 1, 256, 256]             577\n",
      "     BatchNorm2d-115          [-1, 1, 256, 256]               2\n",
      "            ReLU-116          [-1, 1, 256, 256]               0\n",
      "          Conv2d-117          [-1, 1, 256, 256]              10\n",
      "     BatchNorm2d-118          [-1, 1, 256, 256]               2\n",
      "            ReLU-119          [-1, 1, 256, 256]               0\n",
      "      DoubleConv-120          [-1, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 53,955,279\n",
      "Trainable params: 53,955,279\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 2222.50\n",
      "Params size (MB): 205.82\n",
      "Estimated Total Size (MB): 2428.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(elunet,(1,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1315e6714f2518a6216a6eec3b047587d10875bf19b853b35d3e5c84c569e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
